{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c48d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data preprocessing step I- Calculate the presence of each core gene (nucleotide sequence) in the number of strains \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import stat\n",
    "import statistics\n",
    "import numpy as np\n",
    "import timeit\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/pangenome_alignments/'\n",
    "path='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/alleleome/'\n",
    "\n",
    "df=pd.read_csv(path + 'df_pangene_summary_v2.csv')\n",
    "core_gene_list = (df['pangenome_class_2'].eq('Core').groupby(df['Gene']).any()).pipe(lambda x:x.index[x].tolist())\n",
    "genes_df = pd.DataFrame()\n",
    "for k in core_gene_list:\n",
    "    s=0\n",
    "    i=0\n",
    "    nuc_allele_file = MAIN_DIR + k + '/input/'\n",
    "    nuc_file=  nuc_allele_file + 'pangenes.fna'\n",
    "    f=open(nuc_file,'r+')\n",
    "    for seq_record in SeqIO.parse(nuc_file, \"fasta\"):\n",
    "        g_id=seq_record.id\n",
    "        l_gene=len(seq_record)\n",
    "        i=i+1\n",
    "        s=s+l_gene\n",
    "    df=pd.DataFrame.from_dict({\n",
    "    \"Gene\":k,\n",
    "    \"Number_of_strains\":i,\n",
    "    }, orient='index')\n",
    "    df=df.T\n",
    "    genes_df=pd.concat([df,genes_df])\n",
    "    genes_df.to_csv(os.path.join(path,'Genes_nuc_length_number_of_strains.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing step II- Extract only the genes which are present in greater than 5% of strains giving the set of genes to be further studied\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/pangenome_alignments/'\n",
    "path='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/alleleome/'\n",
    "\n",
    "df=pd.read_csv(path +'Genes_nuc_length_number_of_strains.csv')\n",
    "df_genes=df[df.Number_of_strains < 2].index\n",
    "df.drop(df_genes, inplace=True)\n",
    "df.to_csv(os.path.join(path,'Final_nuc_genes_present_in_above_5_percent_of_strains.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4296fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing stepIII- Get the locus tag and length of each allele (nucleotide sequence) of the set of genes\n",
    "import pandas as pd\n",
    "import os\n",
    "import stat\n",
    "import statistics\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/pangenome_alignments/'\n",
    "path='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/alleleome/'\n",
    "\n",
    "df=pd.read_csv(path +'df_pangene_summary_v2.csv')\n",
    "core_gene_list = (df['pangenome_class_2'].eq('Core').groupby(df['Gene']).any()).pipe(lambda x:x.index[x].tolist())\n",
    "genes_df = pd.DataFrame()\n",
    "for k in core_gene_list:\n",
    "    s=0\n",
    "    gene_length=[]\n",
    "    i=0\n",
    "    nuc_allele_file = MAIN_DIR + k + '/input/'\n",
    "    nuc_file=  nuc_allele_file + 'pangenes.fna'\n",
    "    f=open(nuc_file,'r+')\n",
    "    for seq_record in SeqIO.parse(nuc_file, \"fasta\"):\n",
    "        g_id=seq_record.id\n",
    "        l_gene=len(seq_record)\n",
    "        gene_length.append(l_gene)\n",
    "        i=i+1\n",
    "        s=s+l_gene\n",
    "        df=pd.DataFrame.from_dict({\n",
    "        \"Gene\":k,\n",
    "        \"Locus_tag\":g_id,    \n",
    "        \"Length_of_allele\":l_gene,    \n",
    "        }, orient='index')\n",
    "        df=df.T\n",
    "        genes_df=pd.concat([df,genes_df])\n",
    "        genes_df.to_csv(os.path.join(path,'Genes_nuc_length_of_alleles.csv'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing stepIV- Calculate mean length, standard deviation of the length of the set of genes\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/pangenome_alignments/'\n",
    "path='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/alleleome/'\n",
    "\n",
    "df=pd.read_csv(path + 'Genes_nuc_length_of_alleles.csv')\n",
    "new_df = df.groupby(['Gene']).Length_of_allele.agg({'mean','std'})\n",
    "new_df['mean']=new_df['mean'].apply(lambda x:round(x,0))\n",
    "new_df['std']=new_df['std'].apply(lambda x:round(x,2))\n",
    "new_df.to_csv(os.path.join(path,'core_nuc_alleles_with_mean_std.csv'))\n",
    "df = df.merge(new_df, left_on=['Gene'], right_index=True)\n",
    "df.to_csv(os.path.join(path,'core_nuc_alleles_with_locus_mean_std.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45289cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing stepV-Get the genes with their alleles with length less than two standard deviation of the mean length \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/pangenome_alignments/'\n",
    "path='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/alleleome/'\n",
    "df1=pd.read_csv(path +'core_nuc_alleles_with_locus_mean_std.csv')\n",
    "df1['mean_2std']=(df1['mean']- 2*df1['std'])\n",
    "df2=df1[df1.Length_of_allele < df1.mean_2std]\n",
    "df2.to_csv(os.path.join(path,'core_alleles_with_length_less_than_2std_less_than_mean_length.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dfeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing stepVI-Removal of amino acid sequences with specific locus tag with length which is less than two standard deviation of the mean length from the pangenome and create a new file of final set of alleles (of amino acid sequences).In this step\n",
    "#the new file is created only of those genes in which alleles with prescribed length conditions are matched. \n",
    "import glob\n",
    "from webbrowser import get\n",
    "from Bio.Blast import NCBIXML\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import sys\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/pangenome_alignments/'\n",
    "path='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/alleleome/'\n",
    "\n",
    "df=pd.read_csv(path + 'core_alleles_with_length_less_than_2std_less_than_mean_length.csv')\n",
    "gene_locus_list=df['Gene'].to_list()\n",
    "gene_locus_list=set(gene_locus_list)\n",
    "locus_list=df['Locus_tag'].to_list()\n",
    "sequences=[]\n",
    "for s in gene_locus_list:\n",
    "    aa_allele_path = MAIN_DIR + s + '/input/' \n",
    "    aa_file=  aa_allele_path + 'pangenes.faa'\n",
    "    new_file= ''.join(aa_allele_path + 'pan_genes.faa')\n",
    "    f=open(aa_file,'r')\n",
    "    f1=open(new_file,'w')\n",
    "    for seq_record in SeqIO.parse(aa_file, \"fasta\"):\n",
    "        if seq_record.id not in locus_list:\n",
    "            print(seq_record.id)\n",
    "            desc=seq_record.description\n",
    "            allele_seq=str(seq_record.seq)\n",
    "            alleles=''.join(['>'+desc + '\\n'+ allele_seq+'\\n'])\n",
    "            f1.write(alleles)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing stepVII- Rename the unlatered gene file names for further workflow execution.In the previous step, only those genes in which the allelels with less length doesn't exist , their new files will not be created.Hence it is necessary to change the file names of unlatered genes.\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/pangenome_alignments/'\n",
    "path='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/Lactobacillus_helveticus/alleleome/'\n",
    "df=pd.read_csv(path + 'df_pangene_summary_v2.csv')\n",
    "core_gene_list = (df['pangenome_class_2'].eq('Core').groupby(df['Gene']).any()).pipe(lambda x:x.index[x].tolist())\n",
    "#dataframe of core gene alleles with genes not satisfying the condition to be removed\n",
    "df1=pd.read_csv(path + 'core_alleles_with_length_less_than_2std_less_than_mean_length.csv')\n",
    "edit_list=df1['Gene'].to_list()\n",
    "new_gene_list=set(edit_list)\n",
    "for f in core_gene_list:\n",
    "    print(f)\n",
    "    if f not in new_gene_list:\n",
    "        print(f)\n",
    "        aa_allele_path = MAIN_DIR + f + '/input/' \n",
    "        aa_file=  aa_allele_path + 'pangenes.faa'\n",
    "        new_file= aa_allele_path + 'pan_genes.faa'\n",
    "        os.rename(*(os.path.join(aa_allele_path, fname) for fname in (aa_file, new_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d16b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing stepVIII-Create new output directory to save the results of the further processing.\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "from os.path import join, getsize\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/'\n",
    "species_list=['Lactobacillus_paragasseri', 'Lacticaseibacillus_rhamnosus', 'Weissella_cibaria', 'Lactobacillus_crispatus', 'Oenococcus_oeni', 'Pediococcus_pentosaceus', 'Pediococcus_acidilactici', 'Lactobacillus_acidophilus', 'Ligilactobacillus_ruminis', 'Lacticaseibacillus_paracasei', 'Lactobacillus_gasseri', 'Levilactobacillus_brevis', 'Lactobacillus_delbrueckii', 'Latilactobacillus_sakei', 'Lentilactobacillus_parabuchneri', 'Limosilactobacillus_reuteri', 'Leuconostoc_inhae', 'Leuconostoc_mesenteroides', 'Lactobacillus_johnsonii', 'Lactiplantibacillus_pentosus', 'Ligilactobacillus_salivarius','Lactiplantibacillus_plantarum','Lactobacillus_helveticus', 'Lactobacillus_iners', 'Weissella_confusa', 'Limosilactobacillus_fermentum']\n",
    "j=0\n",
    "for k in species_list:\n",
    "    MAIN_DIR_1= MAIN_DIR + k + '/pangenome_alignments/'\n",
    "    query_list_1=[name for name in os.listdir(MAIN_DIR_1) if os.path.isdir(os.path.join(MAIN_DIR_1, name))]\n",
    "    for i in query_list_1:\n",
    "        root_dir = os.path.join(MAIN_DIR_1 + i +'/')\n",
    "        dir=\"output\"\n",
    "        path = os.path.join(root_dir, dir)\n",
    "        j=j+1\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e550925",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alleleome generation step I- Get the consensus of the allels (amino acid sequance) of each gene in the core pangenome\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import AlignIO\n",
    "from pathlib import Path\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast import NCBIWWW\n",
    "import stat\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio import SearchIO\n",
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align.Applications import MafftCommandline\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "import collections\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/'\n",
    "species_list=['Lactobacillus_paragasseri', 'Lacticaseibacillus_rhamnosus', 'Weissella_cibaria', 'Lactobacillus_crispatus', 'Oenococcus_oeni', 'Pediococcus_pentosaceus', 'Pediococcus_acidilactici', 'Lactobacillus_acidophilus', 'Ligilactobacillus_ruminis', 'Lacticaseibacillus_paracasei', 'Lactobacillus_gasseri', 'Levilactobacillus_brevis', 'Lactobacillus_delbrueckii', 'Latilactobacillus_sakei', 'Lentilactobacillus_parabuchneri', 'Limosilactobacillus_reuteri', 'Leuconostoc_inhae', 'Leuconostoc_mesenteroides', 'Lactobacillus_johnsonii', 'Lactiplantibacillus_pentosus', 'Ligilactobacillus_salivarius','Lactiplantibacillus_plantarum','Lactobacillus_helveticus', 'Lactobacillus_iners', 'Weissella_confusa', 'Limosilactobacillus_fermentum']\n",
    "for i in species_list:\n",
    "    MAIN_DIR_1= MAIN_DIR + i + '/alleleome/'\n",
    "    MAIN_DIR_2= MAIN_DIR + i + '/pangenome_alignments/'\n",
    "    df=pd.read_csv(MAIN_DIR_1 + 'df_pangene_summary_v2.csv')\n",
    "    core_aa_query_list = (df['pangenome_class_2'].eq('Core').groupby(df['Gene']).any()).pipe(lambda x:x.index[x].tolist())\n",
    "    for k in core_aa_query_list:\n",
    "        aa_allele_file = MAIN_DIR_2 + k + '/input/' \n",
    "        aa_file=  aa_allele_file + 'pan_genes.faa'\n",
    "        if os.stat(aa_file).st_size == 0:\n",
    "            print(\"The file is empty\")\n",
    "            pass\n",
    "        else:\n",
    "            mafft_cline = MafftCommandline(input=aa_file)\n",
    "            stdout, stderr = mafft_cline()\n",
    "            mafft_out_file=''.join(MAIN_DIR_2+ k +'/output/'+ 'mafft_thresh_aa_' + k +'.fasta' )\n",
    "            with open(mafft_out_file, \"w\") as handle:\n",
    "                handle.write(stdout)\n",
    "            myalign = AlignIO.read(mafft_out_file, \"fasta\")\n",
    "            summary = AlignInfo.SummaryInfo(myalign)\n",
    "            consensus = summary.dumb_consensus(threshold=0.5)\n",
    "            seq=str(consensus)\n",
    "            seq=seq.upper()\n",
    "            consensus_aa_file = os.path.join(MAIN_DIR_2 + k + '/input/'+ 'consensus_nuc_thresh'+ k +'.faa')\n",
    "            consensus_aa = open(consensus_aa_file, 'w+')\n",
    "            consensus_seq= ''.join(['>' + k +'\\n'+ seq])        \n",
    "            consensus_aa.write(consensus_seq)\n",
    "            consensus_aa.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8692703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alleleome generation step II- Alignment of each allele sequnces (amino acid sequence) of each gene with consensus sequence using BLASTp.\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pathlib\n",
    "from os.path import join, getsize\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/'\n",
    "species_list=['Lactobacillus_paragasseri', 'Lacticaseibacillus_rhamnosus', 'Weissella_cibaria', 'Lactobacillus_crispatus', 'Oenococcus_oeni', 'Pediococcus_pentosaceus', 'Pediococcus_acidilactici', 'Lactobacillus_acidophilus', 'Ligilactobacillus_ruminis', 'Lacticaseibacillus_paracasei', 'Lactobacillus_gasseri', 'Levilactobacillus_brevis', 'Lactobacillus_delbrueckii', 'Latilactobacillus_sakei', 'Lentilactobacillus_parabuchneri', 'Limosilactobacillus_reuteri', 'Leuconostoc_inhae', 'Leuconostoc_mesenteroides', 'Lactobacillus_johnsonii', 'Lactiplantibacillus_pentosus', 'Ligilactobacillus_salivarius','Lactiplantibacillus_plantarum','Lactobacillus_helveticus', 'Lactobacillus_iners', 'Weissella_confusa', 'Limosilactobacillus_fermentum']\n",
    "\n",
    "for i in species_list:\n",
    "    MAIN_DIR_1= MAIN_DIR + i + '/alleleome/'\n",
    "    MAIN_DIR_2= MAIN_DIR + i + '/pangenome_alignments/'\n",
    "    df=pd.read_csv(MAIN_DIR_1 + 'df_pangene_summary_v2.csv')\n",
    "    core_aa_query_list = (df['pangenome_class_2'].eq('Core').groupby(df['Gene']).any()).pipe(lambda x:x.index[x].tolist())\n",
    "    import subprocess\n",
    "    blast_path='/home/azureuser/datadrive/ncbi-blast-2.13.0+/bin/blastp'\n",
    "    for r in range(len(core_aa_query_list)):\n",
    "        query=core_aa_query_list[r]\n",
    "        if (pd.isnull(query)==False):\n",
    "            out_file_name = MAIN_DIR_2 + query + '/output/' + 'amino_acid_' + 'blast_out_thresh' + query + '.xml'\n",
    "            args = (blast_path,\n",
    "                    '-query', MAIN_DIR_2 + query + '/input/'+'pan_genes.faa',\n",
    "                    '-subject', MAIN_DIR_2 + query + '/input/'+ 'consensus_aa_thresh'+ query +'.faa' ,\n",
    "                    '-outfmt', '5',\n",
    "                )\n",
    "            with open(out_file_name, 'w+') as outfile:\n",
    "                subprocess.run(args, stdout=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alleleome generation step III- Parsing the results and generating the amino acid mutations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "MAIN_DIR='/Users/arcsan/Documents/allele_from_pan_genome_data_analysis/data/data1/pan_gene/Lactobacillus/'\n",
    "species_list=['Lactobacillus_paragasseri', 'Lacticaseibacillus_rhamnosus', 'Weissella_cibaria', 'Lactobacillus_crispatus', 'Oenococcus_oeni', 'Pediococcus_pentosaceus', 'Pediococcus_acidilactici', 'Lactobacillus_acidophilus', 'Ligilactobacillus_ruminis', 'Lacticaseibacillus_paracasei', 'Lactobacillus_gasseri', 'Levilactobacillus_brevis', 'Lactobacillus_delbrueckii', 'Latilactobacillus_sakei', 'Lentilactobacillus_parabuchneri', 'Limosilactobacillus_reuteri', 'Leuconostoc_inhae', 'Leuconostoc_mesenteroides', 'Lactobacillus_johnsonii', 'Lactiplantibacillus_pentosus', 'Ligilactobacillus_salivarius','Lactiplantibacillus_plantarum','Lactobacillus_helveticus', 'Lactobacillus_iners', 'Weissella_confusa', 'Limosilactobacillus_fermentum']\n",
    "\n",
    "# String parsing helper functions\n",
    "# fast find all chars in string: https://stackoverflow.com/questions/52452911/finding-all-positions-of-a-character-in-a-string\n",
    "def _find_all_idx(string, character):\n",
    "    idx = string.find(character)\n",
    "    while idx != -1:\n",
    "        yield idx\n",
    "        idx = string.find(character, idx + 1)\n",
    "        \n",
    "def _get_char_idxs_in_str(s, c):\n",
    "    char_idxs = list(_find_all_idx(s, c))\n",
    "    char_idxs = [x for x in char_idxs]\n",
    "    return char_idxs\n",
    "    \n",
    "\n",
    "CHAR_OF_INTEREST = '-'\n",
    "assert(_get_char_idxs_in_str('AR-D-G', CHAR_OF_INTEREST)==[2,4])\n",
    "\n",
    "# BLAST results glossary: https://www.ncbi.nlm.nih.gov/books/NBK62051/\n",
    "# Description of special characters on the match string: https://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp\n",
    "# The databases alignments are displayed as pairs of matches between query and subject sequence.\n",
    "# A middle line between the query and subject sequence displays the status of a letter.\n",
    "# For protein alignments (e.g, BLASTP/BLASTX/TBLASTN), identities present the letter,\n",
    "# conservative substitutions present a \"+\", and nothing otherwise. This is the default view.\n",
    "# https://www.ncbi.nlm.nih.gov/books/NBK62051/: \"If the aligned residues have similar physico-chemical properties or have a\n",
    "# positive score in the governing scoring matrix the substitution is said to be conservative.\"\n",
    "# '-' in subject string indicate an insertion\n",
    "# BLAST subject and query results string are always the same length.\n",
    "# Won't find differences in the beginning of genes since doesn't compare query vs subject start and end match positions.\n",
    "# This logic was removed since alleles can have enormous differences on either of their sequences.\n",
    "# Best to keep the returned data seperate for finding\n",
    "# consecutive mutations according to AA positions.\n",
    "\n",
    "BLAST_INDEL_CHAR = '-'\n",
    "def _get_ins_d(subject_str, query_str, subject_match_start_pos):\n",
    "    ins_d = dict()\n",
    "    for idx in _get_char_idxs_in_str(subject_str, BLAST_INDEL_CHAR):\n",
    "        pos = idx+subject_match_start_pos\n",
    "        ins_d[pos] = query_str[idx]\n",
    "    return ins_d\n",
    "\n",
    "# Won't find differences in the beginning of genes since doesn't compare query vs subject start and end match positions.\n",
    "def _get_del_d(subject_str, query_str, subject_match_start_pos):\n",
    "    del_d = dict()\n",
    "    for idx in _get_char_idxs_in_str(query_str, BLAST_INDEL_CHAR):\n",
    "        pos = idx+subject_match_start_pos\n",
    "        del_d[pos] = subject_str[idx]\n",
    "    return del_d\n",
    "    \n",
    "sbjct = 'AR-D-G'  # insertion @ 3 and 5\n",
    "qry = '-RBDHG'  # deletion @ 1\n",
    "assert(_get_ins_d(sbjct, qry, 1)=={3: 'B', 5: 'H'})\n",
    "assert(_get_ins_d(sbjct, qry, 2)=={4: 'B', 6: 'H'})  # test effects of subject_match_start_pos\n",
    "\n",
    "assert(_get_del_d(sbjct, qry, 1)=={1: 'A'})\n",
    "assert(_get_del_d(sbjct, qry, 2)=={2: 'A'})  # test effects of subject_match_start_pos\n",
    "\n",
    "\n",
    "ALL_AMINO_ACIDS = {'A','R','N','D','B','C','E','Q','Z','G','H','I','L','K','M','F','P','S','T','W','Y','V'}\n",
    "\n",
    "def _get_sub_aa_d(subject_str, match_str, query_str, indel_aa_pos_l, subject_match_start_pos):\n",
    "    seq_chng_d = dict()\n",
    "    \n",
    "    for c_i in range(0, len(match_str)):\n",
    "        if match_str[c_i] not in ALL_AMINO_ACIDS:  # finding BLAST characters indicating mismatch or gap\n",
    "            pos = subject_match_start_pos+c_i  # subject_match_start_pos+c_i since subject_match_start_pos represents the first charater and the index c_i == 0\n",
    "            if pos not in indel_aa_pos_l:\n",
    "                seq_chng_d[pos] = {'s':subject_str[c_i], 'q':query_str[c_i]}\n",
    "    \n",
    "    return seq_chng_d\n",
    "\n",
    "\n",
    "\n",
    "assert(_get_sub_aa_d('ARPGCQ', '+ PG Q', 'MTPGBQ', [], 1)=={1: {'s':'A', 'q':'M'}, 2: {'s':'R', 'q':'T'}, 5: {'s':'C', 'q':'B'}})\n",
    "assert(_get_sub_aa_d('ARPGCQ', '+ PG Q', 'MTPGBQ', [5], 1)=={1: {'s':'A', 'q':'M'}, 2: {'s':'R', 'q':'T'}})  # testing use of indel_aa_pos_l\n",
    "assert(_get_sub_aa_d('ARPGCQ', '+ PG Q', 'MTPGBQ', [], 2)=={2: {'s':'A', 'q':'M'}, 3: {'s':'R', 'q':'T'}, 6: {'s':'C', 'q':'B'}})  # test effects of subject_match_start_pos\n",
    "\n",
    "\n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def _get_consecutive_pos_l(pos_l):\n",
    "    cnsc_pos_l = []\n",
    "    for k, g in groupby(enumerate(pos_l), lambda ix : ix[0] - ix[1]):\n",
    "        cnsc_pos_l.append(list(map(itemgetter(1), g)))\n",
    "    return cnsc_pos_l\n",
    "\n",
    "mut_pos_l = [1, 4,5, 7,8,9, 22]\n",
    "assert(_get_consecutive_pos_l(mut_pos_l)==[[1], [4, 5], [7, 8, 9], [22]])\n",
    "\n",
    "\n",
    "import glob\n",
    "from Bio.Blast import NCBIXML\n",
    "gene_var_df = pd.DataFrame()\n",
    "\n",
    "for i in species_list:\n",
    "    MAIN_DIR_1= MAIN_DIR + i + '/alleleome/'\n",
    "    MAIN_DIR_2= MAIN_DIR + i + '/pangenome_alignments/'\n",
    "    df=pd.read_csv(MAIN_DIR_1 + 'df_pangene_summary_v2.csv')\n",
    "    core_aa_query_list = (df['pangenome_class_2'].eq('Core').groupby(df['Gene']).any()).pipe(lambda x:x.index[x].tolist())\n",
    "    for blast_output_file in core_aa_query_list:\n",
    "        blast_file_name= MAIN_DIR_2 + blast_output_file + '/output/'\n",
    "        blast_output_file_path = blast_file_name + 'amino_acid_blast_out_thresh'+ blast_output_file + '.xml'\n",
    "        gene = blast_output_file.replace(blast_file_name,'').replace('.xml','')\n",
    "        for record in NCBIXML.parse(open(blast_output_file_path)):\n",
    "            if len(record.alignments) > 0:\n",
    "                #Description of available members: https://biopython.org/docs/1.75/api/Bio.Blast.Record.html\n",
    "                subject_match_start_pos = record.alignments[0].hsps[0].sbjct_start\n",
    "                blast_subject_str = record.alignments[0].hsps[0].sbjct\n",
    "                blast_match_str = record.alignments[0].hsps[0].match\n",
    "                blast_query_str = record.alignments[0].hsps[0].query\n",
    "                length_align = record.alignments[0].hsps[0].align_length\n",
    "                align_score = record.alignments[0].hsps[0].score\n",
    "                num_align= record.alignments[0].hsps[0].num_alignments\n",
    "                e_value=record.alignments[0].hsps[0].expect\n",
    "                num_indentities= record.alignments[0].hsps[0].identities\n",
    "                ref_id= record.alignments[0].hit_id\n",
    "                ref_info= record.alignments[0].hit_def # new added#### column name to be added####\n",
    "                query_info= record.query\n",
    "                query_info=query_info.split(\"|\", 1)\n",
    "                query_description=query_info[0]\n",
    "                query_description=query_description.split(\" \", 1)\n",
    "                query_id=query_description[0]\n",
    "                query_desc=query_description[1]\n",
    "                GCF_id=query_info[1]\n",
    "                # Won't find differences in the beginning of genes since doesn't compare query vs subject start and end match positions.\n",
    "                ins_d = _get_ins_d(blast_subject_str, blast_query_str, subject_match_start_pos)\n",
    "                for cnsc_pos_l in _get_consecutive_pos_l(ins_d.keys()):\n",
    "                    seq_chng_str = ''.join([ins_d[p] for p in cnsc_pos_l])\n",
    "                    df = pd.DataFrame.from_dict({\n",
    "                        'Gene': gene,\n",
    "                        \"Mutation_source\": \"Pangenome variant\",\n",
    "                        \"AA_start_pos\": min(cnsc_pos_l),\n",
    "                        \"AA_end_pos\" : max(cnsc_pos_l),\n",
    "                        \"Mutation_size\": len(cnsc_pos_l),\n",
    "                        \"AA_mutation_type\": \"Insertion\",\n",
    "                        'AA_cons_seq': '',\n",
    "                        \"AA_seq_change\": seq_chng_str,\n",
    "                        \"Length_alignment\": length_align,\n",
    "                        \"Score\" : align_score,\n",
    "                        \"E_value\": e_value,\n",
    "                        \"Identity\" : num_indentities,\n",
    "                        \"Query_locus_tag\" : query_id,\n",
    "                        \"Query_description\" : query_desc,\n",
    "                        \"GCF_id\" : GCF_id,\n",
    "                        \"Sequence_type\": \"Variant\",\n",
    "                    }, orient='index')  # Can't use columns due to diff parsing of 'AA range' input\n",
    "                    df = df.T\n",
    "                    gene_var_df = pd.concat([df, gene_var_df]) # Accounting for multiples of same allele\n",
    "                # Won't find differences in the beginning of genes since doesn't compare query vs subject start and end match positions.\n",
    "                del_d = _get_del_d(blast_subject_str, blast_query_str, subject_match_start_pos)\n",
    "                for cnsc_pos_l in _get_consecutive_pos_l(del_d.keys()):\n",
    "                    seq_chng_str = ''.join([del_d[p] for p in cnsc_pos_l])\n",
    "                    df = pd.DataFrame.from_dict({\n",
    "                            'Gene': gene,\n",
    "                            \"Mutation_source\": \"Pangenome variant\",\n",
    "                            \"AA_start_pos\": min(cnsc_pos_l),\n",
    "                            \"AA_end_pos\" : max(cnsc_pos_l),\n",
    "                            \"Mutation_size\": len(cnsc_pos_l),\n",
    "                            \"AA_mutation_type\": \"Deletion\",\n",
    "                            'AA_cons_seq': seq_chng_str,\n",
    "                            \"AA_seq_change\": '',\n",
    "                            \"Length_alignment\": length_align,\n",
    "                            \"Score\" : align_score,\n",
    "                            \"E_value\": e_value,\n",
    "                            \"Identity\" : num_indentities,\n",
    "                            \"Query_locus_tag\" : query_id,\n",
    "                            \"Query_description\" : query_desc,\n",
    "                            \"GCF_id\" : GCF_id,\n",
    "                            \"Sequence_type\": \"Variant\",\n",
    "                    }, orient='index')  # Can't use columns due to diff parsing of 'AA range' input\n",
    "                    df = df.T\n",
    "                    gene_var_df = pd.concat([df, gene_var_df]) # Accounting for multiples of same allele\n",
    "                sub_d = _get_sub_aa_d(\n",
    "                        blast_subject_str,\n",
    "                        blast_match_str,\n",
    "                        blast_query_str,\n",
    "                list(ins_d.keys()) + list(del_d.keys()),\n",
    "                subject_match_start_pos)\n",
    "                for cnsc_pos_l in _get_consecutive_pos_l(sub_d.keys()):\n",
    "                    seq_ref_str = ''.join([sub_d[p]['s'] for p in cnsc_pos_l])\n",
    "                    seq_chng_str = ''.join([sub_d[p]['q'] for p in cnsc_pos_l])\n",
    "                    df = pd.DataFrame.from_dict({\n",
    "                            'Gene': gene,\n",
    "                            \"Mutation_source\": \"Pangenome variant\",\n",
    "                            \"AA_start_pos\": min(cnsc_pos_l),\n",
    "                            \"AA_end_pos\" : max(cnsc_pos_l),\n",
    "                            \"Mutation_size\": len(cnsc_pos_l),\n",
    "                            \"AA_mutation_type\": \"Substitution\",\n",
    "                            'AA_cons_seq': seq_ref_str,\n",
    "                            \"AA_seq_change\": seq_chng_str,\n",
    "                            \"Length_alignment\": length_align,\n",
    "                            \"Score\" : align_score,\n",
    "                            \"E_value\": e_value,\n",
    "                            \"Identity\" : num_indentities,\n",
    "                            \"Query_locus_tag\" : query_id,\n",
    "                            \"Query_description\" : query_desc,\n",
    "                            \"GCF_id\" : GCF_id,\n",
    "                            \"Sequence_type\": \"Variant\",\n",
    "                    }, orient='index')  # Can't use columns due to diff parsing of 'AA range' input\n",
    "                    df = df.T\n",
    "                    gene_var_df = pd.concat([df, gene_var_df]) # Accounting for multiples of same allele\n",
    "        gene_var_df.to_csv(os.path.join(MAIN_DIR_1,'pan_aa_gene_vars_df'  + '.csv'))          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
